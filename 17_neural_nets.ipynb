{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priya1016/NLP/blob/main/17_neural_nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "BgKMvFgB7C_g"
      },
      "source": [
        "# Lecture 17. Neural Networks\n",
        "\n",
        "## Agenda\n",
        "\n",
        "1. Feedforward Neural Networks\n",
        "2. Neural Language Models\n",
        "3. Computational Graphs\n",
        "4. Backpropagation\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of the lecture you should able to:\n",
        "1. Explain the differences between linear models such as logistic regression and neural networks\n",
        "2. Identify the main components of a feedforwad neural network\n",
        "3. Explain how feedforward neural language models work\n",
        "4. Describe the backpropagation algorithm\n",
        "\n",
        "\n",
        "## Readings\n",
        "\n",
        "Book Chapters: \n",
        "\n",
        "- 7. Neural Networks and Neural Language Models\n",
        "\n",
        "\n",
        "**Attribution**: _This notebook is based on materials created by Prof Felix Muzny for a previous offering of the course_\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture Activities \n",
        "\n",
        "Feel free to add cells to this notebook as you wish. Make sure to keep **code** and any **answers to questions** that you've written and turn in your notebook as a pdf at the end of the lecture. If you have not finished the exercises, don't worry, you can keep working on them until the end of the week.\n",
        "\n",
        "All lecture notebooks for a given week must be submitted to Gradescope by **11 pm on Sundays**.\n",
        "\n",
        "### Notebook submission\n",
        "\n",
        "Follow these steps to convert your notebook into a pdf for submission: \n",
        "1. Kernel -> Restart & Run All (clear your kernel's memory and run all cells)\n",
        "2. File -> Download As -> .html -> open in a browser -> print to pdf\n",
        "\n",
        "(The download as pdf option doesn't preserve formatting and output as nicely as taking the step \"through\" html, but will do if the above doesn't work for you.)"
      ],
      "metadata": {
        "id": "c0WpuD0_Gr0m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Add your name here"
      ],
      "metadata": {
        "id": "4CSIm-hfNX5E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNer6y6CeTyG"
      },
      "source": [
        "Task 1: Writing a neural net from scratch\n",
        "-----------------\n",
        "Go through the code below and answer the following questions:\n",
        "(For your reference, comments have been added in the code block according to the question numbers)\n",
        "\n",
        "1. What logical function does this dataset represent? (remember that this function should apply to two inputs (our two input features and produce the matching label)\n",
        "\n",
        "  __YOUR ANSWER HERE__\n",
        "\n",
        "2. Does the hidden layer have a bias term in this neural net? \n",
        "\n",
        "  __YOUR ANSWER HERE__\n",
        "\n",
        "3. What variables' values are updated as the loop above iterates? \n",
        "\n",
        "  __YOUR ANSWER HERE__\n",
        "\n",
        "4. How many iterations did you need for the predicted values $\\hat y$ to match the actual values?\n",
        "\n",
        " __YOUR ANSWER HERE__\n",
        "\n",
        "5. Make a graph of how the `layer2_error` changes as epochs progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBsdM7-aeTyG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "# seed random number generation so that you can \n",
        "# track the same numbers as each other\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BiN_mpgeTyH"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x: float) -> float:\n",
        "    \"\"\"\n",
        "    Apply the sigmoid function (1 / (1 + e^(-x)))\n",
        "    to the passed in value.\n",
        "    Parameters:\n",
        "        x - float value to pass through sigmoid\n",
        "    Return:\n",
        "    float in [0, 1]\n",
        "    \"\"\"\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "def sigmoid_deriv(x: float) -> float:\n",
        "    \"\"\"\n",
        "    Apply the derivative of the sigmoid function\n",
        "    sigmoid(x) * (1 - sigmoid(x))\n",
        "    to the passed in value.\n",
        "    Parameters:\n",
        "        x - float value to pass through sigmoid derivative\n",
        "    Return:\n",
        "    float result\n",
        "    \"\"\"\n",
        "    return sigmoid(x) * (1 - sigmoid(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji2teKPAeTyH"
      },
      "outputs": [],
      "source": [
        "# ANSWER QUESTION 1 FROM HERE\n",
        "\n",
        "# input dataset\n",
        "# 3rd \"feature\" is the bias term\n",
        "X = np.array([  [0,0,1],\n",
        "                [0,1,1],\n",
        "                [1,0,1],\n",
        "                [1,1,1] ])\n",
        "    \n",
        "# labels, transposed so that they match\n",
        "# easily with our inputs X\n",
        "# the first label matches the first row in our input data,\n",
        "# the second label matches the second row in our input data, etc\n",
        "# .T gets the transpose for us, which makes \n",
        "# matrix math easier later\n",
        "y = np.array([[0,1,1,0]]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before answering questions 2 & 3, complete the following :\n",
        "\n",
        "Task 1.1 : Fill in dimensions for W and U. Fill these in as a tuple like (rows, columns)"
      ],
      "metadata": {
        "id": "5OSnChh-bCQr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRSzxGXheTyH"
      },
      "outputs": [],
      "source": [
        "# ANSWER QUESTIONS 2 & 3 FROM HERE\n",
        "\n",
        "hidden_units = 4\n",
        "input_features = X.shape[1]\n",
        "\n",
        "# initialize weights randomly with mean 0 and range [-1, 1]\n",
        "\n",
        "# Task 1.1\n",
        "W_dim = FILL ME IN\n",
        "\n",
        "# you'll need to use W_dim and U_dim to produce the correct number of random numbers\n",
        "W = 2 * np.random.random(W_dim) - 1\n",
        "\n",
        "# note that we are doing binary classification, so the second dimension here is 1 \n",
        "# (corresponding to one output unit)\n",
        "U_dim = (hidden_units, 1)\n",
        "U = 2 * np.random.random(U_dim) - 1\n",
        "print(\"W:\", W)\n",
        "print(\"U:\", U)\n",
        "\n",
        "\n",
        "inputs = X\n",
        "num_epochs = 1000\n",
        "for i in range(num_epochs):\n",
        "    # forward propagation—sigmoid\n",
        "    h = sigmoid(np.dot(inputs,W))\n",
        "    \n",
        "    # always sigmoid—classification\n",
        "    y_hat = sigmoid(np.dot(h,U))\n",
        "\n",
        "    # how much did we miss?\n",
        "    layer2_error = y - y_hat\n",
        "    \n",
        "    # this is telling us how much to move\n",
        "    # our weights and in what direction\n",
        "    # use the corresponding derivative to the non-linearity used above\n",
        "    layer2_delta = layer2_error * sigmoid_deriv(y_hat)\n",
        "\n",
        "    # how much did each L1 value contribute to \n",
        "    # the L2 error (according to the weights)?\n",
        "    layer1_error = layer2_delta.dot(U.T)\n",
        "    \n",
        "    # this is telling us how much to move\n",
        "    # our weights and in what direction\n",
        "    layer1_delta = layer1_error * sigmoid_deriv(h)\n",
        "\n",
        "    U += h.T.dot(layer2_delta)\n",
        "    W += inputs.T.dot(layer1_delta)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before answering questions 4 & 5, complete the following:\n",
        "\n",
        "Task 1.2 : Write the code to assign labels to the test data. Fill in values for variables 'h' and 'y_hat' in the code below."
      ],
      "metadata": {
        "id": "dIfP8Ie_bvma"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFIssu3leTyI"
      },
      "outputs": [],
      "source": [
        "# ANSWER QUESTIONS 4 & 5 FROM HERE\n",
        "\n",
        "print(\"Output After Training:\")\n",
        "# these are the same as the inputs that we trained this net on\n",
        "test_inputs = np.array([  [0,0,1],\n",
        "                [0,1,1],\n",
        "                [1,0,1],\n",
        "                [1,1,1] ])\n",
        "gold_labels = np.array([[0,1,1,0]]).T\n",
        "\n",
        "# Task 1.2\n",
        "h = FILL ME IN\n",
        "y_hat = FILL ME IN\n",
        "\n",
        "\n",
        "# These should match with each other\n",
        "# y was our gold labels from the beginning\n",
        "print(\"Actual labels:\", gold_labels.T)\n",
        "print(\"Assigned probabilities:\", y_hat)\n",
        "print(\"Assigned labels:\", [1 if y_hat_val > .5 else 0 for y_hat_val in y_hat])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCYSuETqeTyJ"
      },
      "source": [
        "Task 2: Neural Nets from libraries\n",
        "----------------\n",
        "\n",
        "Now, we'll take a look at some common libraries used to create classifiers using neural nets. We'll take a look at [`keras`](https://keras.io/) which provides a nice API for implementing neural nets and can be run on top of TensorFlow, CNTK, or Theano. We'll look at an example using [`tensorflow`](https://github.com/tensorflow/tensorflow) as our backend.\n",
        "\n",
        "Installation of component libraries:\n",
        "\n",
        "```\n",
        "pip3 install tensorflow\n",
        "sudo pip3 install keras\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go through the code below and answer the following questions:\n",
        "\n",
        "(For your reference, comments have been added in the code block according to the question numbers)\n",
        "\n",
        "6. How many epochs did you need for 100% accuracy? \n",
        "\n",
        "  __YOUR ANSWER HERE__"
      ],
      "metadata": {
        "id": "BGw9y8SUcj61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vo8v9mdxeTyJ"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrGb2laOeTyJ"
      },
      "outputs": [],
      "source": [
        "# set up the basis for a feed forward network\n",
        "model = Sequential()\n",
        "\n",
        "# same X and y as above\n",
        "X = np.array([  [0,0,1],\n",
        "                [0,1,1],\n",
        "                [1,0,1],\n",
        "                [1,1,1] ])\n",
        "y = np.array([[0,1,1,0]]).T\n",
        "\n",
        "# hidden layer\n",
        "# you can play around with different activation functions\n",
        "model.add(Dense(units=4, activation='relu', input_dim=X.shape[1]))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# configure the learning process\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, y, epochs=1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vslf3_nmeTyJ"
      },
      "outputs": [],
      "source": [
        "x_test = np.array([  [0,0,1],\n",
        "                [0,1,1],\n",
        "                [1,0,1],\n",
        "                [1,1,1] ])\n",
        "y_test = np.array([[0,1,1,0]]).T\n",
        "labels = model.predict(x_test)\n",
        "print(\"Assigned probabilities:\", labels)\n",
        "print(\"Assigned labels:\", [1 if y_hat_val > .5 else 0 for y_hat_val in labels])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}